{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04E_NMT_SEq2SeqModels&Attention_NLP-class_Emines_Jan2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igmim-yassine/Pytorch-Tutorial/blob/master/04E_NMT_SEq2SeqModels%26Attention_NLP_class_Emines_Jan2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Summary: Build a Machine Translation Algorithm with Seq2Seq Model and Attention mechanism\n",
        "In this notebook, you will learn: \n",
        "* Preprocess a french-english sentences dataset for machine translation\n",
        "> Dataset available here: https://drive.google.com/drive/folders/1npjvI_9qFKuamCLwlG8fG9lzZZCrsowT?usp=sharing\n",
        "* Build an sequence to sequence model with Bahdanau attention on the dataset\n",
        "> This is the implementation of this paper: \n",
        "https://arxiv.org/pdf/1409.0473.pdf\n",
        "* Train the Machine Translation algorithm \n",
        "* Translate French to English sentences using the trained Seq2Seq Model. \n",
        "\n"
      ],
      "metadata": {
        "id": "dRmDVLG4xkKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import collections"
      ],
      "metadata": {
        "id": "x934D2H1x8ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the dataset\n",
        "* unicode normalization: https://docs.python.org/3/library/unicodedata.html\n",
        "* There is punctuation to remove.\n",
        "* The text contains uppercase and lowercase.\n",
        "* There are special characters => use `string.printable` to remove it.\n",
        "* There are duplicate phrases in English with different translations in French.\n",
        "* The file is ordered by sentence length with very long sentences toward the end of the file."
      ],
      "metadata": {
        "id": "dLYP7JkXy-a2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS5zzqPuxYQ-"
      },
      "outputs": [],
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "  # open the file as read only\n",
        "  file = open(filename, mode='rt' , encoding='utf-8')\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  # close the file\n",
        "  file.close()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split a loaded document into sentences\n",
        "def to_pairs(doc):\n",
        "  lines = doc.strip().split('\\n') # split document by line\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "  return pairs"
      ],
      "metadata": {
        "id": "BCT7piVyzHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean a list of lines\n",
        "def clean_pairs_fn(lines):\n",
        "  cleaned = list()\n",
        "  # prepare regex for char filtering\n",
        "  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "  for pair in lines:\n",
        "    clean_pair = list()\n",
        "    for line in pair:\n",
        "      # normalize unicode characters\n",
        "      line = normalize('NFD' , line).encode('ascii' , 'ignore')\n",
        "      line = line.decode('UTF-8')\n",
        "      # remove \"-\" in composed words \"serre-toi\", etc...\n",
        "      line = line.replace(\"-\", \" \")\n",
        "      # remove \"'\" in composed words \"j'ai\", etc...\n",
        "      line = line.replace(\"'\", \" \")\n",
        "      # tokenize on white space\n",
        "      line = line.split()\n",
        "      # convert to lowercase\n",
        "      line = [word.lower() for word in line]\n",
        "      # remove punctuation from each token\n",
        "      line = [re_punc.sub('', w) for w in line]\n",
        "      # remove non-printable chars form each token\n",
        "      line = [re_print.sub('', w) for w in line]\n",
        "      # remove tokens with numbers in them\n",
        "      line = [word for word in line if word.isalpha()]\n",
        "      # Add <SOS> + <EOS> token\n",
        "      line = [\"<SOS>\"] + line + [\"<EOS>\"]\n",
        "      # store as string\n",
        "      clean_pair.append(' '.join(line))\n",
        "    cleaned.append(clean_pair)\n",
        "  return np.array(cleaned)"
      ],
      "metadata": {
        "id": "UdXiO9ytzjen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "  dump(sentences, open(filename, 'wb'))\n",
        "  print('Saved: %s' % filename)"
      ],
      "metadata": {
        "id": "wNMI2xoSdjfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/MyDrive/12_Teaching/UM6P-NLP-Jan2022/notebooks/fra-eng/fra.txt'\n",
        "doc = load_doc(filename)\n",
        "# split into english-french pairs\n",
        "pairs = to_pairs(doc)\n",
        "print(\"number of pairs\", len(pairs))\n",
        "for i in range(50):\n",
        "  print(pairs[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT73bQBiBD3n",
        "outputId": "f23fdf01-54d2-424f-e486-3d50fef9f9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of pairs 192341\n",
            "['Go.', 'Va !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']\n",
            "['Go.', 'Marche.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)']\n",
            "['Go.', 'Bouge !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)']\n",
            "['Hi.', 'Salut !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']\n",
            "['Hi.', 'Salut.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']\n",
            "['Run!', 'Cours\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)']\n",
            "['Run!', 'Courez\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)']\n",
            "['Run!', 'Prenez vos jambes à vos cous !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)']\n",
            "['Run!', 'File !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)']\n",
            "['Run!', 'Filez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077455 (sacredceltic)']\n",
            "['Run!', 'Cours !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #4580779 (franlexcois)']\n",
            "['Run!', 'Fuyez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #7957917 (Micsmithel)']\n",
            "['Run!', 'Fuyons !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #7957918 (Micsmithel)']\n",
            "['Run.', 'Cours\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #906331 (sacredceltic)']\n",
            "['Run.', 'Courez\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #906332 (sacredceltic)']\n",
            "['Run.', 'Prenez vos jambes à vos cous !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077449 (sacredceltic)']\n",
            "['Run.', 'File !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077454 (sacredceltic)']\n",
            "['Run.', 'Filez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077455 (sacredceltic)']\n",
            "['Run.', 'Cours !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #4580779 (franlexcois)']\n",
            "['Run.', 'Fuyez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #7957917 (Micsmithel)']\n",
            "['Run.', 'Fuyons !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #7957918 (Micsmithel)']\n",
            "['Who?', 'Qui ?', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)']\n",
            "['Wow!', 'Ça alors\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)']\n",
            "['Duck!', 'À terre\\xa0!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #6288793 (Whidou)']\n",
            "['Duck!', 'Baisse-toi\\xa0!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #6288797 (Whidou)']\n",
            "['Duck!', 'Baissez-vous\\xa0!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #6288799 (Whidou)']\n",
            "['Fire!', 'Au feu !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)']\n",
            "['Help!', \"À l'aide\\u202f!\", 'CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)']\n",
            "['Hide.', 'Cache-toi.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #8907581 (CK) & #9934893 (codl)']\n",
            "['Hide.', 'Cachez-vous.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #8907581 (CK) & #9934894 (codl)']\n",
            "['Jump!', 'Saute.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #2416938 (Micsmithel)']\n",
            "['Jump.', 'Saute.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Micsmithel)']\n",
            "['Stop!', 'Ça suffit\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (CM) & #516030 (Goofy)']\n",
            "['Stop!', 'Stop\\u202f!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (CM) & #626567 (U2FS)']\n",
            "['Stop!', 'Arrête-toi !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #448320 (CM) & #1157663 (sacredceltic)']\n",
            "['Wait!', 'Attends !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #1157682 (sacredceltic)']\n",
            "['Wait!', 'Attendez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #1157684 (sacredceltic)']\n",
            "['Wait!', 'Attendez.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #7693749 (Micsmithel)']\n",
            "['Wait.', 'Attends !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #1157682 (sacredceltic)']\n",
            "['Wait.', 'Attendez !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #1157684 (sacredceltic)']\n",
            "['Wait.', 'Attends.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #5137155 (gege_veggie)']\n",
            "['Wait.', 'Attendez.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #7693749 (Micsmithel)']\n",
            "['Begin.', 'Commencez.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #6102432 (mailohilohi) & #7956660 (Micsmithel)']\n",
            "['Begin.', 'Commence.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #6102432 (mailohilohi) & #7957931 (Micsmithel)']\n",
            "['Go on.', 'Poursuis.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #588132 (sacredceltic)']\n",
            "['Go on.', 'Continuez.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6463161 (Aiji)']\n",
            "['Go on.', 'Poursuivez.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6463162 (Aiji)']\n",
            "['Hello!', 'Bonjour !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #373345 (Aiji)']\n",
            "['Hello!', 'Salut !', 'CC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #509819 (Aiji)']\n",
            "['I see.', 'Je comprends.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2111796 (CK) & #1511205 (Hikari)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean sentences\n",
        "clean_pairs = clean_pairs_fn(pairs)\n",
        "# save clean pairs to file\n",
        "save_clean_data(clean_pairs, 'english-french.pkl')\n",
        "# spot check\n",
        "for i in range(50):\n",
        "  print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FONK14EG0WOx",
        "outputId": "19f4f969-99e0-40e5-bfa5-23c27bd5cccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: english-french.pkl\n",
            "[<SOS> go <EOS>] => [<SOS> va <EOS>]\n",
            "[<SOS> go <EOS>] => [<SOS> marche <EOS>]\n",
            "[<SOS> go <EOS>] => [<SOS> bouge <EOS>]\n",
            "[<SOS> hi <EOS>] => [<SOS> salut <EOS>]\n",
            "[<SOS> hi <EOS>] => [<SOS> salut <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> cours <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> courez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> prenez vos jambes a vos cous <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> file <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> filez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> cours <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> fuyez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> fuyons <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> cours <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> courez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> prenez vos jambes a vos cous <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> file <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> filez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> cours <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> fuyez <EOS>]\n",
            "[<SOS> run <EOS>] => [<SOS> fuyons <EOS>]\n",
            "[<SOS> who <EOS>] => [<SOS> qui <EOS>]\n",
            "[<SOS> wow <EOS>] => [<SOS> ca alors <EOS>]\n",
            "[<SOS> duck <EOS>] => [<SOS> a terre <EOS>]\n",
            "[<SOS> duck <EOS>] => [<SOS> baisse toi <EOS>]\n",
            "[<SOS> duck <EOS>] => [<SOS> baissez vous <EOS>]\n",
            "[<SOS> fire <EOS>] => [<SOS> au feu <EOS>]\n",
            "[<SOS> help <EOS>] => [<SOS> a l aide <EOS>]\n",
            "[<SOS> hide <EOS>] => [<SOS> cache toi <EOS>]\n",
            "[<SOS> hide <EOS>] => [<SOS> cachez vous <EOS>]\n",
            "[<SOS> jump <EOS>] => [<SOS> saute <EOS>]\n",
            "[<SOS> jump <EOS>] => [<SOS> saute <EOS>]\n",
            "[<SOS> stop <EOS>] => [<SOS> ca suffit <EOS>]\n",
            "[<SOS> stop <EOS>] => [<SOS> stop <EOS>]\n",
            "[<SOS> stop <EOS>] => [<SOS> arrete toi <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attends <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attendez <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attendez <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attends <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attendez <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attends <EOS>]\n",
            "[<SOS> wait <EOS>] => [<SOS> attendez <EOS>]\n",
            "[<SOS> begin <EOS>] => [<SOS> commencez <EOS>]\n",
            "[<SOS> begin <EOS>] => [<SOS> commence <EOS>]\n",
            "[<SOS> go on <EOS>] => [<SOS> poursuis <EOS>]\n",
            "[<SOS> go on <EOS>] => [<SOS> continuez <EOS>]\n",
            "[<SOS> go on <EOS>] => [<SOS> poursuivez <EOS>]\n",
            "[<SOS> hello <EOS>] => [<SOS> bonjour <EOS>]\n",
            "[<SOS> hello <EOS>] => [<SOS> salut <EOS>]\n",
            "[<SOS> i see <EOS>] => [<SOS> je comprends <EOS>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The clean data contains a little over 190,000 phrase pairs and some of the pairs toward the end\n",
        "of the file are very long. This is a good number of examples for developing a small translation\n",
        "model. The complexity of the model increases with the number of examples, length of phrases,\n",
        "and size of the vocabulary. Although we have a good dataset for modeling translation, we will\n",
        "simplify the problem slightly to dramatically reduce the size of the model required, and in turn\n",
        "the training time required to fit the model.\n",
        "\n",
        "You can explore developing a model on the fuller dataset as an extension; I would love to\n",
        "hear how you do. We will simplify the problem by reducing the dataset to the first 50,000\n",
        "examples in the file; these will be the shortest phrases in the dataset. Further, we will then\n",
        "stake the first 40,000 of those as examples for training and the remaining 10,000 examples to test\n",
        "the fit model."
      ],
      "metadata": {
        "id": "UpPqWXKi0khM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from pickle import dump\n",
        "from numpy.random import shuffle\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "  return load(open(filename, 'rb'))\n",
        "# load dataset\n",
        "raw_dataset = load_clean_sentences('english-french.pkl')\n",
        "# reduce dataset size\n",
        "n_sentences = 50000\n",
        "dataset = raw_dataset[:n_sentences, :]\n",
        "# random shuffle\n",
        "shuffle(dataset)\n",
        "# split into train/test\n",
        "train, test = dataset[:40000], dataset[40000:]\n",
        "# save\n",
        "save_clean_data(dataset, 'english-french-both.pkl')\n",
        "save_clean_data(train, 'english-french-train.pkl')\n",
        "save_clean_data(test, 'english-french-test.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTAg0b-_07Ip",
        "outputId": "cd10170b-b945-4e34-fd0b-7a630829470f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: english-french-both.pkl\n",
            "Saved: english-french-train.pkl\n",
            "Saved: english-french-test.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "dataset = load_clean_sentences('english-french-both.pkl')\n",
        "train = load_clean_sentences('english-french-train.pkl')\n",
        "test = load_clean_sentences('english-french-test.pkl')"
      ],
      "metadata": {
        "id": "lVJCToFd1YT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "  tokenizer = Tokenizer() # create an tokenizer object\n",
        "  tokenizer.fit_on_texts(lines) # Build the vocabulary\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "Adg4WLw31mtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max sentence length - used for padding. \n",
        "def max_length(lines):\n",
        "  return max(len(line.split()) for line in lines)"
      ],
      "metadata": {
        "id": "0ZacM2oe1t8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1 # for padding token.\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare french tokenizer\n",
        "fr_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "fr_vocab_size = len(fr_tokenizer.word_index) + 1 # for padding token. \n",
        "fr_length = max_length(dataset[:, 1])\n",
        "print('French Vocabulary Size: %d ' % fr_vocab_size)\n",
        "print('French Max Length: %d ' % (fr_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZC_yhAh1v9a",
        "outputId": "463e8955-7d91-4777-ace7-44fae3bad7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary Size: 5933\n",
            "English Max Length: 9\n",
            "French Vocabulary Size: 10313 \n",
            "French Max Length: 17 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  # integer encode sequences\n",
        "  X = tokenizer.texts_to_sequences(lines)\n",
        "  # pad sequences with 0 values\n",
        "  X = pad_sequences(X, maxlen=length, padding='post')\n",
        "  return X"
      ],
      "metadata": {
        "id": "xFSvjJtB2Vue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(fr_tokenizer, fr_length, train[:, 1])\n",
        "print(\"train input shape\", trainX.shape)\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "print(\"train target shape\", trainY.shape)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(fr_tokenizer, fr_length, test[:, 1])\n",
        "print(\"test input shape\", testX.shape)\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "print(\"test input shape\", testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krOFRW6M2hlo",
        "outputId": "98315fd4-6f72-42d3-99de-14a414d2a49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train input shape (40000, 17)\n",
            "train target shape (40000, 9)\n",
            "test input shape (10000, 17)\n",
            "test input shape (10000, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YlR7mu5wr97",
        "outputId": "22b1cfc6-a66d-46ef-99af-7413b4941253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,  82, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(trainX)\n",
        "BATCH_SIZE = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(BUFFER_SIZE) # tensorflow dataset. \n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((testX, testY)).shuffle(BUFFER_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "UhZWdT30377P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The encoder/decoder model\n",
        "\n",
        "The following diagram shows an overview of the model. At each time-step the decoder's output is combined with a weighted sum over the encoded input, to predict the next word. The diagram and formulas are from [Luong's paper](https://arxiv.org/abs/1508.04025v5).\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">"
      ],
      "metadata": {
        "id": "-Phh5Og95QJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The encoder\n",
        "\n",
        "Start by building the encoder, the blue part of the diagram above.\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs.\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a `layers.GRU`).\n",
        "5. Returns:\n",
        "  * The processed sequence. This will be passed to the attention head.\n",
        "  * The internal state. This will be used to initialize the decoder"
      ],
      "metadata": {
        "id": "gW4_ZFP25fmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    # attributes\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(input_dim=self.input_vocab_size, output_dim=embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(units=self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens) # (batch, seq_len, embedding_dim)\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    \n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ],
      "metadata": {
        "id": "JafMrAty4pj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE ENCODER\n",
        "embedding_dim = 32\n",
        "units= 128\n",
        "encoder = Encoder(fr_vocab_size,\n",
        "                    embedding_dim, units)\n",
        "for (input_tokens, target_tokens)  in train_dataset.take(1):\n",
        "  # Encode the input sequence.\n",
        "  example_enc_output, example_enc_state = encoder(input_tokens)\n",
        "\n",
        "  print(f'Input batch tokens, shape (batch, s): {input_tokens.shape}')\n",
        "  print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "  print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WehjYhrp5r8F",
        "outputId": "ccfee9b3-288e-438f-8283-059101567929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch tokens, shape (batch, s): (64, 17)\n",
            "Encoder output, shape (batch, s, units): (64, 17, 128)\n",
            "Encoder state, shape (batch, units): (64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The attention head\n",
        "\n",
        "The decoder uses attention to selectively focus on parts of the input sequence.\n",
        "The attention takes a sequence of vectors as input for each example and returns an \"attention\" vector for each example. This attention layer is similar to a `layers.GlobalAveragePoling1D` but the attention layer performs a _weighted_ average.\n",
        "\n",
        "Let's look at how this works:\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/images/attention_equation_1.jpg?raw=1\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/images/attention_equation_2.jpg?raw=1\" alt=\"attention equation 2\" width=\"800\">"
      ],
      "metadata": {
        "id": "gPV_8a_D7G2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where:\n",
        "* $s$ is the encoder index.\n",
        "* $t$ is the decoder index.\n",
        "* $\\alpha_{ts}$ is the attention weights.\n",
        "* $h_s$ is the sequence of encoder outputs being attended to (the attention \"key\" and \"value\" in general attention model terminology).\n",
        "* $h_t$ is the the decoder state attending to the sequence (the attention \"query\" in general attention model terminology).\n",
        "* $c_t$ is the resulting context vector.\n",
        "* $a_t$ is the final output combining the \"context\" and \"query\".\n",
        "\n",
        "The equations:\n",
        "\n",
        "1. Calculates the attention weights, $\\alpha_{ts}$, as a softmax across the encoder's output sequence.\n",
        "2. Calculates the context vector as the weighted sum of the encoder outputs."
      ],
      "metadata": {
        "id": "NegpvM8N8FEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last is the $score$ function. Its job is to calculate a scalar logit-score for each key-query pair. There are two common approaches:\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/images/attention_equation_4.jpg?raw=1\" alt=\"attention equation 4\" width=\"800\">\n",
        "\n",
        "This tutorial uses [Bahdanau's additive attention](https://arxiv.org/pdf/1409.0473.pdf).  \n",
        " TensorFlow includes implementations of both as `layers.Attention` and\n",
        "`layers.AdditiveAttention`. The class below handles the weight matrices in a pair of `layers.Dense` layers, and calls the builtin implementation.  \n",
        "See documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention\n",
        "\n"
      ],
      "metadata": {
        "id": "IJwDpknr8MTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    # attention layer\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query) # query = h_t of decoder\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_value = self.W2(value) # value = h_s of the encoder. \n",
        "\n",
        "    # compute masks\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool) # shape (batch, query_sequence_length)\n",
        "    value_mask = mask\n",
        "\n",
        "    # compute attention vector using self.attention\n",
        "    context_vector, attention_weights = self.attention(inputs=[w1_query, value, w2_value], mask=[query_mask, value_mask], return_attention_scores=True)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "mBkJbozm8GlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE ATTENTION LAYER\n",
        "attention_layer = BahdanauAttention(units)\n",
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(input_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(input_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRN0rnab8l4-",
        "outputId": "1f88bf5b-3545-41e6-9539-465e9ff43ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 128)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(input_tokens != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "zQdiF2o4Ac75",
        "outputId": "9aca64c5-1e6c-4c6a-f99b-8cf497a81f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The decoder\n",
        "\n",
        "The decoder's job is to generate predictions for the next output token.\n",
        "\n",
        "1. The decoder receives the complete encoder output.\n",
        "2. It uses an RNN to keep track of what it has generated so far.\n",
        "3. It uses its RNN output as the query to the attention over the encoder's output, producing the context vector.\n",
        "4. It combines the RNN output and the context vector using Equation 3 (below) to generate the \"attention vector\".\n",
        "5. It generates logit predictions for the next token based on the \"attention vector\".\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/images/attention_equation_3.jpg?raw=1\" alt=\"attention equation 3\" width=\"800\">"
      ],
      "metadata": {
        "id": "AZfMpR-2AlJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ],
      "metadata": {
        "id": "DYiK2Gc7AkW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder takas an input a Nested Input with three elements (new_tokens = target tokens being decoded, enc_output, mask = to mask the padding tokens from the encoder output)"
      ],
      "metadata": {
        "id": "3rPdbVosmF7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NestedInput = collections.namedtuple('NestedInput', ['new_tokens', 'enc_output', 'mask'])\n",
        "#new_tokens = NestedInput.new_tokens\n",
        "#enc_output = NestedInput.enc_output\n",
        "#mask = NestedInput.mask"
      ],
      "metadata": {
        "id": "bVsretaZln-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call(self,\n",
        "         inputs,\n",
        "         state=None):\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "\n",
        "  return logits, attention_weights, state"
      ],
      "metadata": {
        "id": "cMSA5ubTO-Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Decoder.call = call"
      ],
      "metadata": {
        "id": "McwpGYj_Pbys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **encoder** processes its full input sequence with a single call to its RNN."
      ],
      "metadata": {
        "id": "JzG-vgL-PlIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer.word_index[\"sos\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTCfCkseivG5",
        "outputId": "2db95c35-12c4-49c9-d8e0-bc9e162c9a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Decoder. \n",
        "decoder = Decoder(eng_vocab_size,\n",
        "                  embedding_dim, units)\n",
        "\n",
        "start_index = eng_tokenizer.word_index[\"sos\"]\n",
        "first_token = tf.constant([[start_index]] * target_tokens.shape[0])\n",
        "# Run the decoder\n",
        "logits, attn_weights, dec_state = decoder(\n",
        "    inputs = NestedInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(input_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n",
        "# Sample a token according the logits. \n",
        "sampled_token = tf.random.categorical(logits[:, 0, :], num_samples=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqcvQcHlPjlX",
        "outputId": "9d4a110d-adb8-4aa7-be97-a2c35dd65b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 5933)\n",
            "state shape: (batch_size, dec_units) (64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now that you have all the model components, it's time to start training the model. You'll need:\n",
        "\n",
        "- A loss function and optimizer to perform the optimization.\n",
        "- A training step function defining how to update the model for each input/target batch.\n",
        "- A training loop to drive the training and save checkpoints."
      ],
      "metadata": {
        "id": "v6oHsvllRAgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the loss function"
      ],
      "metadata": {
        "id": "2UdnGiM7R0hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred) # y_true (batch, s=9) y_pred (batch, s, output_vocab_size)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    loss *= mask # loss = loss * mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ],
      "metadata": {
        "id": "_2o9pJzdRxO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the training step\n",
        "Start with a model class, the training process will be implemented as the `train_step` method on this model. See [Customizing fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit) for details.\n",
        "\n",
        "Here the `train_step` method is a wrapper around the `_train_step` implementation which will come later. This wrapper includes a switch to turn on and off `tf.function` compilation, to make debugging easier."
      ],
      "metadata": {
        "id": "HAOlj_u8R8X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units, inp_vocab_size, tar_vocab_size,\n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(inp_vocab_size,\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(tar_vocab_size,\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.use_tf_function = use_tf_function\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "twNc4qLeR-oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall the implementation for the `Model.train_step` method is as follows:\n",
        "\n",
        "1. Receive a batch of `input_text, target_text` from the `tf.data.Dataset`.\n",
        "2. Convert those raw text inputs to token-embeddings and masks. \n",
        "3. Run the encoder on the `input_tokens` to get the `encoder_output` and `encoder_state`.\n",
        "4. Initialize the decoder state and loss. \n",
        "5. Loop over the `target_tokens`:\n",
        "   1. Run the decoder one step at a time.\n",
        "   2. Calculate the loss for each step.\n",
        "   3. Accumulate the average loss.\n",
        "6. Calculate the gradient of the loss and use the optimizer to apply updates to the model's `trainable_variables`."
      ],
      "metadata": {
        "id": "oGpxedQvSXHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_masks(self, input_tokens, target_tokens):\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  target_mask = target_tokens != 0\n",
        "  return input_mask, target_mask"
      ],
      "metadata": {
        "id": "7iPJDY1rSWfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_tokens, target_tokens = inputs  \n",
        "\n",
        "  (input_mask, target_mask) = self._create_masks(input_tokens, target_tokens)\n",
        "\n",
        "  max_target_length = target_tokens.shape[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:,t:t+2] # get y_t, y_{t+1}\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask, enc_output, dec_state)\n",
        "\n",
        "      loss += step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables # get all weights of all layers of the tf.keras.Model\n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ],
      "metadata": {
        "id": "1yprqpsNSQH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state)."
      ],
      "metadata": {
        "id": "u6br9T9lTPjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2] # input token as a new_tokens input for the decoder, target_token is for the loss. \n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = NestedInput(new_tokens=input_token, enc_output=enc_output, mask=input_mask)\n",
        "  y_pred, _, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  step_loss = self.loss(target_token, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ],
      "metadata": {
        "id": "nPG2R663TQCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._create_masks = _create_masks\n",
        "TrainTranslator._train_step = _train_step\n",
        "TrainTranslator._loop_step = _loop_step"
      ],
      "metadata": {
        "id": "GObviYK4TSlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the training step\n",
        "Build a `TrainTranslator`, and configure it for training using the `Model.compile` method:"
      ],
      "metadata": {
        "id": "nUbHmO8bTjbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units, inp_vocab_size=fr_vocab_size, tar_vocab_size=eng_vocab_size,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "kAddLxloTlXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss should start around: "
      ],
      "metadata": {
        "id": "SSRqSe_6UAaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(eng_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YRA9NQqT5jp",
        "outputId": "a6986802-5bf3-463d-ed85-8391b4937100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.688285266258644"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step((input_tokens, target_tokens)))\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJhZLQC_URzt",
        "outputId": "78bd332c-69f2-416e-ed7b-251763a0df3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.301533>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.298201>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.2944903>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.2899904>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.284255>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.2767653>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.2668867>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.2538114>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.236515>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.213669>}\n",
            "done\n",
            "CPU times: user 6.28 s, sys: 444 ms, total: 6.73 s\n",
            "Wall time: 5.74 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While it's easier to debug without a tf.function it does give a performance boost. So now that the _train_step method is working, try the tf.function-wrapped _tf_train_step, to maximize performance while training:"
      ],
      "metadata": {
        "id": "Am-rDzB0UWcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.int32, shape=[None, input_tokens.shape[1]]),\n",
        "                               tf.TensorSpec(dtype=tf.int32, shape=[None, target_tokens.shape[1]])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "sh0NRxZtUVuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step\n",
        "translator.use_tf_function = True"
      ],
      "metadata": {
        "id": "ya6BwoQdUbba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first call will be slow, because it traces the function."
      ],
      "metadata": {
        "id": "AEmvefajUkFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator.train_step([input_tokens, target_tokens])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypmYynP0Ukds",
        "outputId": "09a881db-3742-4f25-af03-79bdb210b9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.1835523>}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But after that it's usually 2-3x faster than the eager `train_step` method:"
      ],
      "metadata": {
        "id": "V3mLQAFYU6nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A good test of a new model is to see that it can overfit a single batch of input. Try it, the loss should quickly go to zero:"
      ],
      "metadata": {
        "id": "FSK_WdNzVAPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([input_tokens, target_tokens])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "atiAO2ECU_dv",
        "outputId": "7380eb16-12b2-4b88-f557-e29783395487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffb0c49b150>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you're confident that the training step is working, build a fresh copy of the model to train from scratch:"
      ],
      "metadata": {
        "id": "5H7bPZBLVIP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "units = 256\n",
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units, inp_vocab_size=fr_vocab_size, tar_vocab_size=eng_vocab_size,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "x7VGB8vmVHTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model\n",
        "\n",
        "While there's nothing wrong with writing your own custom training loop, implementing the `Model.train_step` method, as in the previous section, allows you to run `Model.fit` and avoid rewriting all that boiler-plate code. \n",
        "\n",
        "This tutorial only trains for a couple of epochs, so use a `callbacks.Callback` to collect the history of batch losses, for plotting:"
      ],
      "metadata": {
        "id": "z3cp2tsIVaA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs): # method of tf.keras.callbacks.Callback\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ],
      "metadata": {
        "id": "68h4O3kBVGRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_translator.fit(train_dataset, epochs=3,\n",
        "                     callbacks=[batch_loss])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZJZPPVbVvpr",
        "outputId": "e8337b5c-d221-4d81-e767-b587a870af3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 251s 367ms/step - batch_loss: 3.7594\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 258s 413ms/step - batch_loss: 2.6962\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 246s 394ms/step - batch_loss: 2.0234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bd7f5b790>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([2, 5])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/batch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "n2YrqkGfV2V2",
        "outputId": "d17f2e0d-6299-42d0-f73c-a844cd966ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/batch')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZfb48c9Jo1epAhJQBAEpgohYQSyAgmVtPyvW3bWuri7YdXXFul9777r2LigiRVBq6B0CBAGBUEMoIe35/XHvTKbcaUnuZJI579drXpm5c2fmZCBz5mnnEWMMSimlkldKVQeglFKqamkiUEqpJKeJQCmlkpwmAqWUSnKaCJRSKslpIlBKqSTnaiIQkRwRWSwiC0Qky+F+EZHnRSRbRBaJyDFuxqOUUipYWhxeY6AxZnuI+4YAnezLccAr9k+llFJxUtVdQyOA941lJtBYRFpXcUxKKZVU3G4RGOBnETHAa8aY1wPubwNs8Lm90T622fckEbkBuAGgXr16fbp06VLugPYXlrBm214yD6lHg9rxaBAppVTVmzt37nZjTHOn+9z+JDzRGLNJRFoAE0RkhTFmaqxPYieQ1wH69u1rsrKChhuiNu+PXZz/8nReHXksAzu3KPfzKKVUdSIi60Pd52rXkDFmk/0zF/ga6Bdwyiagnc/ttvYx16SI2MG5+SpKKVV9uJYIRKSeiDTwXAfOAJYEnPYdcKU9e6g/kGeM2YyL7DRAqRbbU0opwN2uoZbA12J9A08D/meM+UlE/gpgjHkVGAcMBbKB/cBIF+MByloEmgeUUsriWiIwxqwFejocf9XnugFucisGJ56eIW0RKKWUpaqnj1YZTQNKKWVJukSgXUNKKeUv6RKBd9KQZgKllAKSMBF4WwRVHIdSSiWKpEsEOlislFL+ki8R2D81DyillCX5EoF2DSmllJ8kTATWTx0sVkopS9IlAp0+qpRS/pIuEWitIaWU8pd0iUBbBEop5S/pEoFOH1VKKX9Jlwg8NA0opZQl6RJBSopuTKOUUr6SLhHoYLFSSvlLukSgtYaUUspf0iUCHSxWSil/yZcI7J+aB5RSypJ8iUC7hpRSyk8SJgLrp9YaUkopS9IlAl1ZrJRS/pIuEej0UaWU8pd8icDOBE+PX8mGnfurNhillEoASZgIrEywr7CEv34413t81todZOfuraqwlFKqyqRVdQDxViutLPcVFpd6r1/8+kwAcsYMi3tMSilVlZKuReCbCFZrC0AppZIvEXi6hjwe+HZJFUWilFKJwfVEICKpIjJfRH5wuO9qEdkmIgvsy3VuxxPo/Rnr4/2SSimVUOIxRnAbsBxoGOL+T40xN8chDqWUUg5cbRGISFtgGPCmm68Tq84tG1R1CEoplTDc7hr6P+BuoDTMOReIyCIR+UJE2rkcDwC10pNuaEQppUJy7RNRRM4Gco0xc8Oc9j2QaYzpAUwA3gvxXDeISJaIZG3btq3CsfnOHAIoKCqp8HMqpVR15eZX4xOA4SKSA3wCDBKRD31PMMbsMMYctG++CfRxeiJjzOvGmL7GmL7NmzevcGAZAYngy3kbK/ycSilVXbmWCIwxo40xbY0xmcAlwCRjzOW+54hIa5+bw7EGlV1XKy3V7/bBonA9V0opVbPFfWWxiDwCZBljvgNuFZHhQDGwE7g6HjEEdg3tO1gcj5dVSqmEFJdEYIyZAkyxrz/gc3w0MDoeMfjq0qohPy7Z4r39zIRV8Q5BKaUSRlJOn7l50BE8f2lvx/syR43lo1m6yEwplTySMhGkpgjDex4a8v63flsXx2iUUqpqJWUiiCQloB6RUkrVZJoIHKRoHlBKJZGkTgRZ9w12PK4tAqVUMknqRNCsfi3H44GlqpVSqiZL6kQQinYNKaWSiSYCB9ogUEolk6RPBCd1ahZ0zDNGUFBUwt1fLCQ3vyDeYSmlVNwkfSK4qG9w5etFG/PYklfAj0s281nWRh4ft6IKIlNKqfhI+kQQaobQ9wv/pMSuRaddRUqpmizpE0GoD/k6GamUGgPodFKlVM2W9Ing6DaNHI/XzUiltNSTCOIZkVJKxVfSJ4J2Tes6Hk9PTcHOA9oiUErVaEmfCEK55eP5bMk7AECKNgmUUjWYJoIwnp+UDUCqtgiUUjWYJoIoaINAKVWTaSKIgnYNKaVqMk0EUUgRYcGG3Xw4U3cuU0rVPHHfvL46Wp27l3Nf+h2Ay/u3r+JolFKqcmmLIApTV23zXjf2IjOllKopNBEAXVs3jPrcg8WlLkailFLxp4kA+P6WE8l+bEhU5x4oLHE5GqWUii8dIwBSUwSIbmaQtgiUUjWNtghidLBYWwRKqZpFE0GMTnlqCje8n1XVYSilVKXRROAjPTW67qGfl22N+bkHPT2FzFFjdYxBKZVwNBH4mHTnqbwz8ljv7dVhBpAvfm0GPR/+2buN5cez/+Afny4Ief7a7fsAmLwyt5KiVUqpyuF6IhCRVBGZLyI/ONxXS0Q+FZFsEZklIpluxxNOu6Z1Gdi5BU3qpgNWKepQZq3bSd6BIvo9NpH1O/Yx+qvFfD1/U8TX8Gx2k7N9H3/s2O933/Q12/3WLCilVDzEY9bQbcBywGmy/rXALmPMESJyCfAEcHEcYgpr4p2nknegKOrzl2/O914vKikNm0CW/bmHQV1acOrTUwDIGTPMe9//e2NW0DGllHKbqy0CEWkLDAPeDHHKCOA9+/oXwGkiVV/zuWm9DDo0qwfAq5f3iXj+qK8Wea+/9ds69h0sDnnuy1PWcOvHobuQlFIq3tzuGvo/4G4g1OT7NsAGAGNMMZAHHBJ4kojcICJZIpK1bVt8u07O6t4q4jm795e1Hsb8uIJHvl/mvb1p9wHe+X2d3/lz1++M+vU37trP6K8WU1yi6xeUUu5wLRGIyNlArjFmbkWfyxjzujGmrzGmb/PmzSshOnft2HfQe/3Kt2bxsE9igNi2vrzzs4V8PPsPZudEnzyUUioWbrYITgCGi0gO8AkwSEQ+DDhnE9AOQETSgEbADhdjigvfunS+rQUP3zwQaTppkd0SCDfuoJRSFeHap4sxZrQxpq0xJhO4BJhkjLk84LTvgKvs63+xz6n25T1LfX6FUodfx3cYZM22vWGfq7jUenyabo6jlHJJ3L9misgjIjLcvvkWcIiIZAN3AKPiHY8bSg3s3l9ISalhl0OLwPcz/ewXfnN8jpJSw2dZG9hbYA08a4tAKeWWuBSdM8ZMAabY1x/wOV4AXBiPGOJp38Fiej0ygasHZDreL1EUuDv8nnF+t9OiXPWslFKx0q+ZLthTYLUC3p2e43h/pLFip8J28//YrZviKKVcoYkgBid1ahbVeau2hu/33xNhsdpnWRuDjo3+ajGf+xw/6clJ3P7J/KjiUUqpcDQRRKF1o9qkpgidWjSolOfbFzBTKLCsxII/djs+7u4vF/HBjBwANuw8wDcL/gSsOkefZW2olNiUUslHN6aJwrS7B2KAgqISBndt4S0FUVmufHu2X1mJL+cFtwg87v92KYfUr+W9faCwhNFfLQbgor7tKjUupVRy0BZBFNJSU0hPTaFB7XQGHB5d91CsMkeNjfrcv380z3v9mZ9XuhFOVF6ZsoYBj0+sstdXSlUOTQTl8PM/Tq7S1/edfhqqON5D3y3lrs8XsmDDbv7x6QJKSyt/oPmJn1bwZ15BpT+vUiq+NBGUQ6tGtav09Wunp3qvh/p8f3d6Dp/P3ci1787h6/mb2LGvMOTz7T1YzCez/9BZSUolKU0E5eBZ5Vv1dVL9xxOcylV4EsDQ56eROWqsd2Mc3w/9h79byqivFjNrndYzUioZaSIoh9QQ5R6+uekEhh4duVppJHUzUsPeXxyiGbB970HH4wDb8q37vp2/ibd/W0eH0ePYvd9KEp5k8fD3y9hfGLqEtlKqZtJEUA5pKdbb1sxn9g5Ar3aN6XZoowo///4IhegKi51LUpcaw/MTV/PRrPUhH2uA/05YBVhTUKFszGH55j28NDk79oCVUtWaTh8th9QU4YkLjub4js04+anJfvc1rB36LU1PFYpK3OuH/3bBnzxrf8iHO8fjnBd/Y1iP1n5F8EIlGaVUzRVVi0BEjhSRN0TkZxGZ5Lm4HVwiu/jYwzjskLpBx8/peWjIx/xwy0luhhQxCTgZu2gz+QVlM49SHLq9cvMLWLDBeZGbUqr6i7Zr6HNgHnAfcJfPJen9PmqQ3+3GdTO4b9hRjud2bF7P7/Ztp3VyLa5YzFxbNkj86ZwNZI4ay5+7D3iPXf7mLM596XdK7LGJyStz+XTOH3GPUynljmgTQbEx5hVjzGxjzFzPxdXIqok2jevQuaV/6Yn6tZy7hwJLSaenChcc05bDmga3LKqKZyOdm/5nLVqbtXaHt3bSDnsweuQ7c/jXl4urJkClVKULmwhEpKmINAW+F5G/i0hrzzH7uAK+vmkAs+89zXv7gj5to3qcMfDMRT2ZevdAt0Irt7z9RfyevZ2LX5/pPVYUYraSrj9QqnqLNFg8F2uiiafj2Lc7yAAd3QiquqmbkUbdjLK30mkTmX+P6BZ0LJE/Ptdu3+fXPQSEXJ1sTGKsqVBKlU/YRGCM6RCvQGq6K47PDDrm9EW6TeM6bAr4AK4qgeGFWr+QyAlNKRVZtLOGbhKRxj63m4jI390Lq2YZHmImUb1aZQvHRp6QCSR2N0tJiESQlaMrkpWqzqIdLL7eGOOdP2iM2QVc705INcPrV/Th3yO68cDZXXn+0t5B999/dleu8tnK8rqTou9lC7dWoTLd/cUiv9uhEoHvOIJSqvqJNhGkis+qIxFJBTLcCalmOKNbK644PpNrTnTuXbv2xA5+Ywme+kUN66TzzshjaVQnnROPsEpe33VmZ445zNsg447Tj/R7rk4t6ld2+I5CJQKlVPUW7VfL8cCnIvKafftG4Cd3QkpOLRvW5oGzu3Jm91a0aVyHhQ+ewa59hbwzPYe/nnI4/6/fYZz69BTyDhQF9ckXlpRyaKParpeELk3gbiulVPlF2yK4G5gE/M2+TEQXlJXLMxf25N/ndne875oTO9CmcR3v7Sb1Mrjj9CNJTRGa1MvgvN5tgOBB5tsHd+KnOOyRkJsfXaJZvTXfsRKqUioxRdsiuMUY8xzwqueAiNwGPOdKVDVYtGsMnFx7Ygdmr9vJ8F6HUmoML0zKZuGDZwDxGWS+5t0srjy+veN9+w4Wc9mbs3jwnK6c9/J0Tu/akjeu7Ot6TEqpiou2RXCVw7GrKzEOFYV2Tesy7raTaFa/Fted1NGbBAC/wnFuen+Gc2XT2Tk7WbBhNw9/vwyAmWt3xCUepVTFRVpZfKmIfA90EJHvfC6TAZ0zmKCy7hvsd7tXu8YhzoSMtEqqRB7YIAm4fd17c5i4fKvfsX0Hixnx4m+s2LKncmJQSpVLpK6h6cBmoBnwjM/xfGCR4yNUlRl360m0aVKHg8Vl/fNz7h3M/D92ccMHzqWhPrmhP+e/PL3Cr/2vL63/Dp4qpb55oKCohF+W5/LL8lxyxgwD4OUp2cxYs4OFG/N44scVvDOyX4VjUEqVT6SVxeuB9cDx8QlHVUTXQxsCsH2vtadA19YNad6gFgO7tOCK/u35YGZwt86hjeqw6tEh5OYXcOITk4Puj1Zuvv/uaMYYiktK2bb3IK/9ujbo/Cd/Wum9HmrFslIqPqJdWdxfROaIyF4RKRSREhEJ254XkdoiMltEForIUhF52OGcq0Vkm4gssC/XlfcXUWWa1a/Fkxf04J2RxwJW7aNQM5VSxOoeatukciugGuDRscs5/vFJrNySH/ZcnZaqVNWKdtbQi8AlWPsS9AWuBI4M+wg4CAwyxuwVkXTgNxH50RgTuAz1U2PMzbEErSK76Nh20Z3o4hjzxBXWmMCWPeGnnepCNaWqVtQjhcaYbCDVGFNijHkHOCvC+cYYs9e+mW5f9C8+ATx3Sa+I59wztEuFXsP3S/667fu81z+atZ7MUWP9zvUkgtVb8yO2HpRSlS/aRLBfRDKABSLypIj8I5rHikiqiCwAcoEJxphZDqddICKLROQLEXH8GisiN4hIlohkbdu2LcqQVSgjerWheYNa1g2fD+wfbjnRu6lOSgWnoxqMY3XVe79eEnTMM0Zw+n+ncub/Ta3Q6yqlYhdtIrjCPvdmYB/QDrgg0oPs1kMvoC3QT0QCO6q/BzKNMT2ACcB7IZ7ndWNMX2NM3+bNm0cZsgr07xHduGXQEUBZj5Bvr0z3No3426mHA6F3WYtWQVEpG3dFV0471D4HSqn4iOqv3Riz3m4RZAJfASuNMYXRvogxZre99uAsYInPcd9VR28CT0b7nCp2vnsiNKyTHjTTB+CGkzvSqE46F/Ztx6iv4rMdZUmUg8V5B4poWDstbovnlEoW0c4aGgasAZ7HGjjOFpEhER7T3LOHgYjUAU4HVgSc09rn5nBgefShq4p4d+Sx3DO0C60a1fY7np6awuX925OaEr8P2+KSyIlg654Cej78My9PWROHiJRKLtF2DT0DDDTGnGqMOQUYCPw3wmNaA5NFZBEwB2uM4AcReUREhtvn3GpPLV0I3IqWrYibtk3qcsPJh4c956FzusYllsBZQzPWWA3FHxdv9m56s9murPrz0i1xiUmpZBJtR3C+PWvIYy3W6uKQjDGLgKAdWYwxD/hcHw2MjjIGFWcX9m3HQ3btIDcFdg1d+sZMHj23O/d9Y/UielYjg047U8oNYROBiJxvX80SkXHAZ1h/ixdifctXNVhFZw5Fy2mw+J3f13mv5+0v8g5u69ozpSpfpK6hc+xLbWArcApwKrDNPqZUhTmVmFizrWztQc9HfmbCsq1B58xdv4shz02joEj3PlCqIiJ1DU0AxgfM7lFJIl4Dxht3HeDt39aFPWfWOuu/oLE7hw4Wl3DBK1axvJVb8ukZpsKqUiq8SC2CdsDnIjJNRB4SkeNE5+4ljVAlqp+/NGjop8Ie+SH8WISnm6rUqqfH4+PKJqB9t/BPJq/MDfnYp8evZO76XRUPUqkaKmwiMMY8YYwZBAwFFgLXAPNE5H8icqWItIxHkCqxNKjgYrPy8CSCZZv3UFxSyurcsrkKb/22jpHvhB6yenFytrf1oJQKFu2Csnzga/uCiHQFhgDvA2e6Fp1KOOf1bsOpneO/ujvF5yvLV/M2IQ7V8gY/+yvZuXvp3LIB4+Owh7NSNUWkHcou97l+gue6MWYZcNAYo0kgydx2WidEhJOPDJ0M2h9SuSWtwX8G056CIpw6KLNzrRqHK7fme/dw1vIVSkUWaYzgDp/rLwTcd00lx6ISUJ/2TfxuN6mbEfb8O08/kl/vGsjEO0+p1Dh8E0FRFCuRPedEW75CqWQWKRFIiOtOt1UN9OrlfQBoWi+DJQ+fSaO66QDeb9yBurdtBMDhzevz5d8GVFocvi2A4pJSVm/dG/pkoLCklMd/XM6AMZO8x/IOFFVaPErVJJESgQlx3em2qoE80zVTRCJWJP3g2n4M7NzCezuwNRHo3ZHH0rRe+BaGNw6f/22/ZW+PuNlNYXEpr/26lm0+hfXu/To+RfSUqm4iDRZ3sWsFCXC4fR37dkdXI1MJwfPhf/4xbfyOOzUITuoUPG7QoFYa+QeLHZ/bAAejXAyWnlrWJJi1bmfE8wuLS4OObdi5P6rXUirZREoEPYGWwIaA4+0Arf6VBOpmpLHk4TOpm55arscvftiaTxC4KxlY3Uu3Dz6Sx8ZFLjq7Y1/UVc8BWLY5L+hYNOMFT41fQd/Mpn4tG6VqukhdQ/8F8owx630vQB6Rq4+qGqJ+rTRSAlYZX9i3LQCTKjAoXC8jjetPjq5hOf+P3TE99zXvZpUnJF6avCbsmgSwZiLpbCRVk0RKBC2NMUEdq/axTFciUtXCiF5tyBkzjI7N6wPQpnGdmJ+j66ENKzusqOXmF4T9MH/0h2Xc9flCx/s63jOO83SBmqpBInUNhSvgEvtfvqqRfrnjZJrVrxXVudee2IEebRsxolfZmEOf9k3iWgJiS14B/R+fyK2DjuCOMzp7j+8pKJtV9KZd++ipC3s6PsfCDbG1UJRKZJFaBFkicn3gQRG5DpjrTkiqujmiRQMaR1hfcEX/9gDcf3ZXvyQAUDejfOMP5ZGVs5MF9of485Oy/e7r8dDPcYtDqUQSqUVwO/C1iFxG2Qd/XyADOM/NwFTN8siIbjw0vFuVxrBk0x7+8uoMv2Nb9xTQsmHoiurTVm9jwOHNHCuxjl20mWE9Wjs8SqnqJVLRua3GmAHAw0COfXnYGHO8MUZnDamoiUjEstZndI1/DcPj/jOR3ftDz0i64q3ZvPqr8z7Jo75c5Hhcqeomqj2LjTGTjTEv2JdJkR+hVPQuOfYwADo0rxd0340RZhV1aFb2mAnlLDT3zM+rwg4cr8ktW8W8cktZ1VOdN6Rqimg3r1fKNcN6tCZnzDAa1wkeZ7j1tE6Mu/WkkI89r3fZeENKivDaFX1ifv3UFGHmutB7LxWWlC1OO/P/pnqv7w2xUE6p6kYTgUoYRfYH7l9POdx7LC1V/FYVB/Ld5jItRTizW6uYXzc9Vdh3MPQKZ6tcxRrHRXFvTltLQVEJB4t1u0xVfWkiUAljeM9DqZ2e4l2sBiAI4TbF8+3SSSnn5nlvTFvHlrwDIe8vKinlg5nrHe97dOxyutz/E/3/M7Fcr61UItBEoBJGZrN6rPj3EDo28x8rCDfG7Htf4OrnWNz/7dKQ9xWXGjbuCp0oAHbtT+zKprPX7aTbAz+Rl+BxqqqhiUAlHN8WgFO30MzRp3mvR1uioiKyc8OXvPZVWmq46X/zmG0Xxvtz9wGufHs2u2KslVTZXpi0mn2FJSzYqAvhVDBNBCqhiUjQ7JxWjcrm/TeonU4rex2AWxtkbM4LX/Lao++jv5BfUMzYRZu56u3ZALw/Yz1TV23jo1nOXUtKJQJNBCrhRSoa6tkzoZxDBJVm+96DFJVaA94Hikp4avwKGtWxNvLJLyibYVRQVEJJqWHDzv18NiewsK9S8aeJQCWkFg1q8eA5XWN6jGdD+3pxLFkRqMhnqulLk8sWoi3YsJunxq8AoMv9P3Hde3O45PWZ3P3lIgqi3JOhMoTaWU4lt0glJspNRGoDU4Fa9ut8YYx5MOCcWsD7QB9gB3CxMSbHrZhU9TH73sFRn/vQOd24/9ul3t3OZt87mFJjDfAOeW5a0PktGtQi12fnssq0v9D/Q93TSpm1biez1u3kwj7tAJi8chu10qzvYfH4bA4380opN1sEB4FBxpieQC/gLBHpH3DOtcAuY8wRWPsbPOFiPKqaqp0e/r/pkKNbk3XfYDLsD9Z6tdJoUDudo1o3JM1hJtFRrcOXv756QGa5Y/1m/ia/2zv2+iecU5+eEvSYaDbMUcpNriUCY/FMt0i3L4H/40cA79nXvwBOE/3qogK0bVKXVy/vw8gTMhk9pAsA/To0jeqx00cPCjoWboHaF389vnxB2iYuz/W7nXcg9HRNzx9Dic9aiOlrtpM5aizLN++pUBxKxcLVMQIRSRWRBUAuMMEYMyvglDbY22AaY4qxdj47xOF5bhCRLBHJ2rZtm5shqwR1VvdWPHhON260Vx2/O/JYpt09MOLjWjQIriwarvhd38ymFepHXxbwAf5Z1saIj9mSV8CYH1dQWmoYv8Sq5ThzbVnJi9enrmHT7vDrGJSqCFcTgTGmxBjTC2gL9BOR7uV8nteNMX2NMX2bNw/eIF0ln7oZabRrWrdcj01PDf/fPt4dNbd/uoBXf11Dls/mPLPX7aSk1JCdu5f/jFvBCWMmMWNN6HpI0dJOKOUkLrOGjDG7gcnAWQF3bQLaAYhIGtAIa9BYKdfcMqiT4/GTj7S+ZMS7y37vQav7yLdT9MclW7jirVkMfvZX77FL35jJtws2BT48KtrfqsJxLRGISHMRaWxfrwOcDqwIOO074Cr7+l+ASUbnt6lK9tF1x/HUX3p4bx/uUO76yb/04J2rjwXK1iWMsscj3FZYbE05TRH/ukrTHVoAt32yQKeAqkrnZougNTBZRBYBc7DGCH4QkUdEZLh9zlvAISKSDdwBjHIxHpWkTjiiGRf2bee9nebTNdSuaR1O69KCi/q2Cxo7iNcWmvvtyqf7C4uZsGxrxPMLiqzEMXvdTqZnbwdg0cbdFPusYVAqFq6tIzDGLAJ6Oxx/wOd6AXChWzEoFcm0u4NnFXm+cLvenWK/Tr69r8EVb82O8mHWAy96zdp2c/ztJzP8xd+54eSO3DP0qKheUylfriUCpRLZ/64/zrugK5D3s1KEPu2bMNdnELcyFZbzG3xJwG5q2+21Cks25YV8jE7KVuFoiQmVNA7zmWU04PBm9GnvvBbBt0Xw5d8G8P+OOyzkc57T89DKDDEqoXbV1KEDVV6aCFTSmHjnKax8NHDimhP/InYtGtQKeWavdo0rIbLY9Hz4Z7/bl73pvzynuKSUL+Zu5KLXZngHopUKR7uGVNKItH7Ao6xFELk/JZFm8HjGDp4cv5LXp64F4I+d+ziiRQNtLaiwtEWgVAieFkHbJs4L1z7/6/FB/fWJoDIWnqnkoolAqQCB354vOKYNH157XNB5vds1Dtlf78up8F286WCxCkcTgVIBvBvd2LdFhBM7NQs6T0Qo9ckaZ3RtCcC/zurChH+cTPc2VpXTL/82oNJjzBw1NuiYJxRTgTmiv63ezvkv/65rEpKMJgKlAtxxemdO79qSswNmBP32r4Gc1a2V93aK+I8RXGrPLhre61A6tWxAcYl1X7RjE5XhjalrWbLJt/Cdlc48Ye49WExpQDPG93e447MFzPtjNzuqeI9lFV86WKxUgFaNavPGlX2DjrdtUtdvtbHVIii7f2DnFuSMGea9XVzqSQTx6ZfZln+Qx8YtDzo+dtFmfl1lVe295eP5LN+8h4uPbUfbJnVJTRGGPf8bW/cUMPf+071JS2cbJRdtESgVg9KAAYTA2748A8nhyl5XprXb9zke/yzLf1/kl6es4ZSnpvDcL6sAq3S2pwXgSVrFCTgIrtyjiUCpcujRthEQenEXlO1fnJZSdX9mG3ft97YGAs3O2Rl0zJO0dIwguWgiUCoGns/9kSdkWrfDtAgGHOjedUMAABaySURBVG7tsdSwTvge2OzHhlRGaI7WbnNuJQDMXLvTb9B56qptrLHP1xZBctFEoFQMetsridsfYpWyDreO4NFzj2byP0+lcd2MsM+Z5uJgcloM4xNXvl1W9M4z0K2Sgw4WKxWDqwZkctKRzTm8eX0A+mY2AXCsR5SRlkKHZlbCuGng4bQ/pB6LNu7mw5l/hH2NBQ+czpgfV3DaUS35Zv4mxi7eXO54H/h2abkeV96CeKp60kSgVAxExJsEAAZ1acm8+0+nab3w3/rvOtPa5Oaivu149NyjefSHZbw3I4dLjvVPICv+fRa101MZc4G1kc435dyRrKISqXSGcp8mAqUqKFIScHLf2V257+yuQcdrp/tvhlNQWFLuuCoiEUtnKPfoGIFSCayoij6QL359Jte8OweA3PwC3p+RUyVxqPjQRKBUAvvPed2r7LUnrcgF4OaP5vPAt0tZF7BOYX9hMQ9+u4R99g5rqvrSRKBUAmvbpC6rA6aXtm1SJ64x7NpvLTa78YMsMkeNpcdD4wF4a9o63puxnjenrQv52B17D5I5aqxWRE1wmgiUSgAvX3YMP9xyouN9vrWKcsYM46K+7eIVFlBWuXTV1r0A7CmwWgCebivP6upxizcze53/IrX5f+wG4M1pa73Hdu8vDKp3pKqWJgKlEsDQo1vTvU2jqM69aeARjLv1JObeN9jlqOCjWevZklfgfKfx38nt7x/N46LXZjifav/cln+QXo9M4LmJqys5UlURmgiUqgZO79qSJ/9iTSlNTRG6HtqQQ+rX4t6hR7n6uvd+vcTbAvC1Ja+ADbsOANHt5OaxLf8gAOOXbqGopJQpK3MrJ1BVIZoIlKoG3riyr2OX0PUndwy7p7Jb+j8+ka/nW2scAje9CbUGYUteAc9OWAnAii353PX5Qq5+Zw6z1ur4QVXTRKBUNTf7Xve7iGLRYfQ49hQUAWVJYtKKXPo/PpFflpe1AL5Z8CcA+Q4tDhVfmgiUUhXy7IRVbNy13+/Yrhg2tglcRKfiTxOBUooGtdOol1H+D+Sb/zff73YsFSpqp/t/DE1dtY15f+wKeX5xSSnPT1yt6xcqkSYCpWqQy3yK32UeUjfo/sAP+9O6tCh7bP/25X7dBRt2+90Ot2FPoMCtPK98ezbnvzw95Plfz9/EsxNW8d8Jq2ILUoXkWiIQkXYiMllElonIUhG5zeGcU0UkT0QW2JcH3IpHqWTw2HlH06ZxHWqnp3j3FHj+0t58fH1/AOr4JIJ7hx7FUxf2BOCo1g1jmPsT2Tx7/UDgQLKTWFcUHCiy6i+9Oz2HzFFjydtfFOMzqEButgiKgTuNMV2B/sBNIhJcZQumGWN62ZdHXIxHqaQw9e6BLHnoTO+irWMOa0ynllbFVN8v6sN6tKZpvQw+u/F4xz2aK+Kfny8Mer1QfFsPH8xc771eWFzK0+NXsjegCygrx+o28iS6DQHjEyp2riUCY8xmY8w8+3o+sBxo49brKaUsqSlCWmoKl/Szuoma1M3wftv3/dD1XOvXoSmN6qRXehyPj1tOURQb3Nzz1WLv9fu/WeK9/umcP3hxcjavTMn2O/+7hX/63dZKqRUXlzECEckEegOzHO4+XkQWisiPItItHvEolQxuGXQEqx8bQr1aad59k5v47JYWNN+/MvuGgNemrmX0V4sinrdiSz479xWyfe9Bv+M799lTUCMEVuLze8xdv6tC5Su25BWQOWpsULKp6VxPBCJSH/gSuN0Ysyfg7nlAe2NMT+AF4JsQz3GDiGSJSNa2bc4bcSul/ImIdyC2Ud10HjuvOx9cdxx921u7qnmSg5t2Rdl/f8y/J9D30V/8ju0rtLqE6tVKY39hcciFar+t3k7mqLF8OHM9F7wynTemreWR75cxfumWmONdscX6iPo8a0PMj63OXP2fICLpWEngI2PMV4H3G2P2GGP22tfHAeki0szhvNeNMX2NMX2bN2/uZshK1ViXHdeeNo3r8NoVfXj2op60alTb7/5YSkXEg2d66IGiEro+MJ5nJ6xi0NNTgs571p499MqUNQCszt3L27+v48YP5sb8mp5UI9GMctcgbs4aEuAtYLkx5tkQ57Syz0NE+tnx6HpzpVx0SP1anH9M26oOI6Lv7JXHnsVpL0zKZm3Angi+Nu22ah99MXej91jmqLE88O2SUA8JZmeC5EoD7m5VeQJwBbBYRBbYx+4BDgMwxrwK/AX4m4gUAweAS4xulqpUzJ68oAeN6lb+gG9VyrdbBIs25VXoed6fsZ5HRnRn/Y59HNa0LiKCMYZFG/Po2a6x42OSrEHg6qyh34wxYozp4TM9dJwx5lU7CWCMedEY080Y09MY098YE3oViVIqpIuObceZ3VpVdRiuWBiwWK08ZqzZwSlPTeEzu+//zWnrGPHS78wMKHhnQqxqWLttr9/tvQeLueOzBezeH30pjUSmK4uVUgC0bFhWxfSRETVrAt9KexD4X18u5uelW3jD3igncKaSh2+D4IdFfzLomV+ZuHwrc3J2smprPh/OXM9X8zbxsj0uUd252TWklKpGrjw+k+YNajG0e2tSUoQHvl3qd3+jOunkHaieq3iLfaaU3uAziFzXXmn9edYGjmhR33EB3GK7a2rl1nye/Mkqoz1qSBeg5owlaItAKQVYC9HO7nEoKSnOH2/n9jo05GM7NqvnVliVwrMaOZCn8uldXyzivJenexOB76whz7EUh2NOmSB3TwHDnp8Weme3BKSJQCkV0bS7B3L/2U4VYuCUI5tzSufEntb9U4g1BS9MzOZLn1lGHr6f754Faqk+iWD55j32ecGZ4JM5G1j65x4+9CmXkeg0ESilImrXtC5pqSnkjBnGyUf6f+i/d00//nVWF568oEdMz3lWAgxuz1i7gzvtukgAawIGhQFKva2EsmPhVh6npVonFlej0heaCJRSFVY7PZWLjg3eSjOcC/pYaxkSaarm4z+uAGDyylxvaW3PTCKnRWZOsafZXWvFJaUArN6az3kv/87eg8WUlBoKi0vdCL1CNBEopWISYgghZiWl1gdihwQcXyg1cO5Lv1vXvV1Dwec5vRWe0h2eFsETP61g/h+7mbFmB9e/n8WR9/1I5qixrN8RenGcr+Wb93CwuCT2XyIGmgiUUo7O6ek8OPz4+Udzab/Yvv076dHWWsx148kdK/xcbskcNdanayi6DOjpGnp3eo7f40pKDZNWlO3ZPNnneii5ewoY8tw0v6qsbtBEoJRy9MKlvR2Pt25Uh8fPj3484IyuLR2PH9q4DjljhnHxsYcFjTskkiK7i8epJRSYG0pKTdC0W8/j3vl9XcyvvafAmq47d33orTsrgyYCpZRr2jSuw+sOm958f/OJfrfP6dE6XiHFbLddQdWpReDp/rny7dmcMGYSz/0SvH2mZ0xg1rqdYV9nf2Fx0F7N8Sq4o4lAKVUuHZvV81uN7MSp0nW9jFSObtvI75hnc5nze7fx20fZ48fbTip/oBXk+VbuxPMhP3XVNjbtPsDzk7KDzgm1OU9gYvnn5ws5/+XpjqudjYGnx69kW77zSuiK0pXFSqmQ3rn6WA5tXMfxvkn/PDXo2Jx7B1NUUsqAMZMA/7n3HqkOfSxFdiKonZHqOO3yqNYNI8b66Lnduc+FvnRPVVOn537n9xxmrAldMLm01ETcQe35iavp3KoBy/601ibkFxTTrL5/gl27fR8vTs5myZ95vDuyX6y/QkTaIlBKhTSwSws6t2oQ9fnNG9TySxye1bjf3nQC9WtZ3zvTUoM/dkrsfvj0FGH00C6ceETZtiQ/3R5da+CcHqFXPlfE+h3h90ResSU/5H0d7xnH6tzgtQkA67bvY0teAc9OWMWNH8z1biLkGZNwcqDQndlDmgiUUpXuyuPbA2WDqT3bNWbinacAZfPsfXlaAakpKbRuVIdXr+gDWLWAurSK3BoA526oRBCqsN2703Po//hE721PIjjjv1N5fuJqx8e4NWSQoG+dUqo6u+w4KxH4dgN5PuzDJQLP1MtaadZH01/6hN9Ap3/Hpt7rkaZ3HhqwI1uiSfdZqODZdS2QW9u1aCJQSlU6T7+4b6G2Q+plAPDPMzsHne9ZhetJEumpKSx9+EwePCd8Oey3rjqWa0/s4PfY3oc5bzbjNHspkTh1mQV+7Ls1i0gTgVKq0pWa4ERQOz2VnDHDHLfJvLBvOzq3bMDl/dt7j9WrlebXolj2yJlBj6tXK417hx7FskfOpHZ6Kiv+fRaf3Xi8Y0yeVkaichpYD1TqUibQWUNKqUp32CF1AbjxlOhWDbdsWJvx/zg57Dl1M9KonZ5CQZH/YGpKilA3w/oo85SVdtLUbpEkqvU7I5eccKuOXWKnSKVUtdSwdjo5Y4YxolebSn1ezwfhbad1or2dbKLVpG4GVw/IrNR4KtPWPZHXCLg1WKwtAqVUteEZLL3xlI784/QjY3psSop4p7BWB0s25bFoY57fMbcGi6vPu6KUSnol3plH4Tszuh3akKV/7qFZ/Qz+d31/8u3Vwf06NIXJwefnjBlG5qixlR5vRZz9wm9Bx8J1fVWEJgKlVLVxeteWjF+61XEKqq8v/jqAfYXBK3QTubhdNG4f3MmV59VEoJSqNp67pDc79xWG3FfZo05GKnUynL89L3zwDOas28l172e5EaJX03oZ7NxXWKnPGc3MovLQwWKlVLVROz01ZO2jaDWqk056HKaSPnpu90p/Tqc6TZVBE4FSSuFfGrtFg1oVmm5637CjQu7DUBGRWkLlpV1DSikFfqWxZ987GICXJmfz1PiVMT/Xpf0Oc1wpXFHaNaSUUpUk1DTMh4d34+Pr+3tvj+hVvoqmbq1i1q4hpZRy2VUDMjn+8EO8t9s2qcstg46I+XncaA2Af8mOSn1eV54VEJF2IjJZRJaJyFIRuc3hHBGR50UkW0QWicgxbsWjlFIenvZAz3aNmWN3A4VyRtdWUT9vn/ZN/Ka2+lYUrQzVsUVQDNxpjOkK9AduEpGuAecMATrZlxuAV1yMRyml/DSuk07zBuG32zR22mjjMFspIzWFHvbYwuCjWvDl3waQ/Z+hUb/+Wd2iTzIALjU03EsExpjNxph59vV8YDkQWHhkBPC+scwEGotI4u5irZSqUaIp2ODpjvFNBN/dfAKT/3kqix46gxcu7Q3AaUcFzxISgr/Be84HeOy82KaYutU1JG7VrvB7EZFMYCrQ3Rizx+f4D8AYY8xv9u2JwL+MMVkBj78Bq8UA0BmIfRjf0gzYXs7HxovGWHGJHh8kfoyJHh9ojLFqb4xxXFrt+vRREakPfAnc7psEYmGMeR14vRJiyTLGJPTuFBpjxSV6fJD4MSZ6fKAxViZXZw2JSDpWEvjIGPOVwymbgHY+t9vax5RSSsWJm7OGBHgLWG6MeTbEad8BV9qzh/oDecaYzW7FpJRSKpibXUMnAFcAi0VkgX3sHuAwAGPMq8A4YCiQDewHRroYD1RC91IcaIwVl+jxQeLHmOjxgcZYaeIyWKyUUipx6cpipZRKcpoIlFIqySVNIhCRs0RkpV3OYlQVxeBYdkNEHhKRTSKywL4M9XnMaDvmlSJyZpzizBGRxXYsWfaxpiIyQURW2z+b2MfjXiZERDr7vFcLRGSPiNxele+jiLwtIrkissTnWMzvmYhcZZ+/WkSuikOMT4nICjuOr0WksX08U0QO+LyXr/o8po/9/yPb/j0qbZVTiBhj/nd16+89RHyf+sSW4xkTrar3sFyMMTX+AqQCa4COQAawEOhaBXG0Bo6xrzcAVgFdgYeAfzqc39WOtRbQwf4dUuMQZw7QLODYk8Ao+/oo4An7+lDgR0CwSonMqoJ/2y1A+6p8H4GTgWOAJeV9z4CmwFr7ZxP7ehOXYzwDSLOvP+ETY6bveQHPM9uOW+zfY4jLMcb07+rm37tTfAH3PwM8UJXvYXkuydIi6AdkG2PWGmMKgU+wylvElYmu7IavEcAnxpiDxph1WLOr+rkfachY3rOvvwec63O8KsuEnAasMcasD3OO6++jMWYqsNPhdWN5z84EJhhjdhpjdgETgLPcjNEY87Mxpti+ORNrLU9IdpwNjTEzjfWJ9r7P7+VKjGGE+nd17e89XHz2t/qLgI/DPYfb72F5JEsiaANs8Lm9kfAfwK4Tq+xGb2CWfehmu3n+tqcLgaqL2wA/i8hcscp7ALQ0ZWs8tgCewipV/d5egv8fXiK9j7G+Z1X9Xl6D9e3Uo4OIzBeRX0XkJPtYGzsuj3jFGMu/a1W9jycBW40xq32OJdJ7GFKyJIKEIsFlN14BDgd6AZuxmpdV6URjzDFY1WFvEpGTfe+0v8VU+bxjEckAhgOf24cS7X30SpT3LBQRuRerYvBH9qHNwGHGmN7AHcD/RKRhFYWXsP+uAS7F/0tJIr2HYSVLIkiYUhbiUHbDGLPVGFNijCkF3qCs26JK4jbGbLJ/5gJf2/Fs9XT52D9zqzJG2xBgnjFmqx1vQr2PxP6eVUmcInI1cDZwmZ2wsLtbdtjX52L1uR9px+PbfeR6jOX4d437+ygiacD5wKc+cSfMexhJsiSCOUAnEelgf4u8BKu8RVzZfYhBZTcC+tTPAzwzEr4DLhGRWiLSAWvfhtkux1hPRBp4rmMNJi6xY/HMYrkK+NYnxqoqE+L3DSyR3kef143lPRsPnCEiTezujzPsY64RkbOAu4Hhxpj9Psebi0iqfb0j1nu21o5zj4j0t/8/X+nze7kVY6z/rlXx9z4YWGGM8Xb5JNJ7GFFVjlTH84I1U2MVVla+t4piOBGre2ARsMC+DAU+ABbbx78DWvs85l475pXEYWYB1kyLhfZlqee9Ag4BJgKrgV+ApvZxAV6yY1wM9I3Te1kP2AE08jlWZe8jVkLaDBRh9fleW573DKufPtu+jIxDjNlY/eme/4+v2udeYP/7LwDmAef4PE9frA/jNcCL2BUKXIwx5n9Xt/7eneKzj78L/DXg3Cp5D8tz0RITSimV5JKla0gppVQImgiUUirJaSJQSqkkp4lAKaWSnCYCpZRKcpoIVFITkRK7MuRCEZknIgMinN9YRP4exfNOEZGoNy0XkY/tee+3i8il0T5OqcqgiUAluwPGmF7GmJ7AaODxCOc3BiImgnLINFbhtFOAqS48v1IhaSJQqkxDYBdY9aBEZKLdSlgsIp7qlWOAw+1WxFP2uf+yz1koImN8nu9CEZktIqt8Co75EZGPRGQZ0EWsOvZnAGNF5DrXfkulAri5eb1S1UEd+wO4NtZ+EYPs4wXAecaYPSLSDJgpIt9h7SvQ3RjTC0BEhmCVOD7OGLNfRJr6PHeaMaafWBupPIhVhsCPMeYyEbkQOAz4AnjaGHOhO7+qUs40Eahkd8DnQ/144H0R6Y5VBuI/duXVUqwywS0dHj8YeMfYdXqMMb616r+yf87F2qQklGOwSlH0wCrtoVRcaSJQymaMmWF/+2+OVaumOdDHGFMkIjlYrYZYHLR/luDwt2a3FP6DtbvW2fbr7ROR04wxA8v3WygVOx0jUMomIl2wtjncATQCcu0kMBBrK0yAfKxtRj0mACNFpK79HL5dQ2EZY8YBfbC2Mzwaq0BZb00CKt60RaCSnWeMAKzuoKuMMSUi8hHwvYgsBrKAFQDGmB0i8rtYm5f/aIy5S0R6AVkiUgiMA+6J4fV7AwvtcsnpxtqoSKm40uqjSimV5LRrSCmlkpwmAqWUSnKaCJRSKslpIlBKqSSniUAppZKcJgKllEpymgiUUirJ/X9CuiD5otGulQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translate\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation.\n",
        "\n",
        "For this the model needs to invert the `text => token IDs` mapping provided by the `output_text_processor`. It also needs to know the IDs for special tokens. This is all implemented in the constructor for the new class. The implementation of the actual translate method will follow.\n",
        "\n",
        "Overall this is similar to the training loop, except that the input to the decoder at each time step is a sample from the decoder's last prediction."
      ],
      "metadata": {
        "id": "D_s44gJUWDvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, output_id2word,\n",
        "               output_word2id):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.output_id2word = output_id2word\n",
        "    self.output_id2word[0] = \"<pad>\"\n",
        "    self.output_word2id = output_word2id\n",
        "    self.output_word2id[\"<pad>\"] = 0\n",
        "\n",
        "    token_mask_ids = [self.output_word2id[w] for w in [\"sos\", \"<pad>\"]]\n",
        "    token_mask = np.zeros([len(self.output_id2word)], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = self.output_word2id[\"sos\"]\n",
        "    self.end_token = self.output_word2id[\"eos\"]\n",
        "\n",
        "  def output_token_string_from_index(self, token_ids):\n",
        "    # tokens_ids (batch, seq_len)\n",
        "    tokens_array = []\n",
        "    for i in range(token_ids.shape[0]):\n",
        "      tokens_array.append([self.output_id2word[index] for index in token_ids[i].numpy()])\n",
        "    return tf.constant(tokens_array)"
      ],
      "metadata": {
        "id": "KiClB24rWCQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    output_id2word=eng_tokenizer.index_word,\n",
        "    output_word2id=eng_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "WNbSZekdWRUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "5e79b03a-2016-4104-ddcf-ed4eed835b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-baa242d317b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m translator = Translator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_translator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_translator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_id2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     output_word2id=eng_tokenizer.word_index)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Translator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert token IDs to text\n",
        "The first method to implement is `tokens_to_text` which converts from token IDs to human readable text.  \n",
        "This uses the `tf.strings` module: https://www.tensorflow.org/api_docs/python/tf/strings "
      ],
      "metadata": {
        "id": "WuaPs896WzZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ') #\" \".join(list)\n",
        "  result_text = tf.strings.strip(result_text) # Strip leading and trailing whitespaces from the Tensor.\n",
        "  return result_text # list of decoded sentences over the batch "
      ],
      "metadata": {
        "id": "F0ALKqWGW5KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ],
      "metadata": {
        "id": "5j0h8BA4W_Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input some random token IDs and see what it generates:"
      ],
      "metadata": {
        "id": "RzxPaNl9XCq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=len(eng_tokenizer.index_word)+1)\n",
        "translator.tokens_to_text(example_output_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4XVgCeJXDg7",
        "outputId": "6758afb2-3905-4d59-bcc1-e195dff03d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              "array([b'unreasonable sweated', b'yell shizuoka', b'dozen toothache',\n",
              "       b'practice gentlemen', b'undergrad blinds'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample from the decoder's predictions\n",
        "This function takes the decoder's logit outputs and samples token IDs from that distribution:"
      ],
      "metadata": {
        "id": "WweDPSosXVWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(self, logits, temperature):\n",
        "  # sample with temperature\n",
        "  # if temperature = 0. => greedy decoding. \n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  # if temperature == 0:\n",
        "      # greedy decoding: tf.math.argmax()\n",
        "  # else: \n",
        "      # sampling with temperature: logits / temp + tf.random.categorical(logits/temp)\n",
        "\n",
        "\n",
        "  return new_tokens"
      ],
      "metadata": {
        "id": "b7jLZ3fJXc-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.sample = sample"
      ],
      "metadata": {
        "id": "75_iSdvAXlU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test run this function on some random inputs:"
      ],
      "metadata": {
        "id": "RJymVAgXXswW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_logits = tf.random.normal([5, 1, eng_vocab_size]) # check which size of vocabulary to take. \n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4vk0qkUXvPz",
        "outputId": "3abd60cf-b35d-4895-80ad-99fd9fb4a068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[4377],\n",
              "       [ 565],\n",
              "       [3744],\n",
              "       [2912],\n",
              "       [5852]])>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_tokens, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_tokens)[0]\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    # 1. create a NestedInput for the decoder\n",
        "\n",
        "    # 2. Pass forward on the decoder to obtain logits, attention_weights, decoder_state:\n",
        "\n",
        "\n",
        "    # sample new tokens using self.sample:\n",
        "\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "\n",
        " \n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings using self.token_to_text.\n",
        "  \n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ],
      "metadata": {
        "id": "26_8LcRwXxnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.translate = translate_unrolled"
      ],
      "metadata": {
        "id": "QC_HyNA9YGkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    output_id2word=eng_tokenizer.index_word,\n",
        "    output_word2id=eng_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "pnxBgo42GN58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_text = [\n",
        "    'Il fait très froid ici .', # \"It's really cold here.\"\n",
        "    'C est ma vie .', # \"This is my life.\"\"\n",
        "]\n",
        "max_len = max([len(e.split(' ')) for e in input_text])\n",
        "input_tokens = encode_sequences(tokenizer=fr_tokenizer, length=max_len, lines=input_text)\n",
        "\n",
        "result = translator.translate(\n",
        "     input_tokens = input_tokens)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWOQUSUYarm",
        "outputId": "85f17b82-48d5-4ebb-a00b-f60b2adecbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he is skinny <pad> <pad>\n",
            "that s my problem <pad>\n",
            "\n",
            "CPU times: user 133 ms, sys: 3.09 ms, total: 136 ms\n",
            "Wall time: 134 ms\n"
          ]
        }
      ]
    }
  ]
}